With seed: 79
Creating dict, graph, labels. 
Loaded 93116 datapoints.
Length of annotation dict: 2314
Topics - {1, 2, 5, 8, 10, 13, 14, 15, 16, 20, 22, 25, 26, 27, 29, 31, 63, 64, 68} - {65, 3, 7, 9, 18, 19, 24, 28, 62} - {32, 33, 66, 67, 4, 69, 6, 17, 23}
lengthsss 1521 - 210
Declaring Model. 

============ Epoch 0 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 1.95
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.         0.46190476 0.        ]
Recall: [0. 1. 0.]
F1: [0.         0.63192182 0.        ]
Micro: 0.46190476190476193
============================
For --Stance--
Precision: [0.52857143 0.         0.        ]
Recall: [1. 0. 0.]
F1: [0.69158879 0.         0.        ]
Micro: 0.5285714285714286
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 2.35
  Validation took: 1.9341628551483154

Training complete!
Total training took 0:00:40 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154

============ Epoch 1 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 1.93
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.         0.42982456 0.26041667]
Recall: [0.         0.50515464 0.43859649]
F1: [0.         0.46445498 0.32679739]
Micro: 0.3523809523809524
============================
For --Stance--
Precision: [0.52857143 0.         0.        ]
Recall: [1. 0. 0.]
F1: [0.69158879 0.         0.        ]
Micro: 0.5285714285714286
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 2.53
  Validation took: 1.9329569339752197

Training complete!
Total training took 0:01:19 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197

============ Epoch 2 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 1.58
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.         0.52892562 0.12359551]
Recall: [0.         0.65979381 0.19298246]
F1: [0.         0.58715596 0.15068493]
Micro: 0.35714285714285715
============================
For --Stance--
Precision: [0.52857143 0.         0.        ]
Recall: [1. 0. 0.]
F1: [0.69158879 0.         0.        ]
Micro: 0.5285714285714286
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 2.58
  Validation took: 1.9326908588409424

Training complete!
Total training took 0:01:59 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424

============ Epoch 3 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 1.29
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.   0.44 0.  ]
Recall: [0.         0.90721649 0.        ]
F1: [0.         0.59259259 0.        ]
Micro: 0.41904761904761906
============================
For --Stance--
Precision: [0.49180328 0.         0.22222222]
Recall: [0.81081081 0.         0.09677419]
F1: [0.6122449  0.         0.13483146]
Micro: 0.45714285714285713
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 4.91
  Validation took: 1.9320955276489258

Training complete!
Total training took 0:02:39 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258

============ Epoch 4 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 1.15
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.39130435 0.42138365 0.03571429]
Recall: [0.16071429 0.69072165 0.01754386]
F1: [0.2278481  0.5234375  0.02352941]
Micro: 0.36666666666666664
============================
For --Stance--
Precision: [0.81914894 0.         0.43965517]
Recall: [0.69369369 0.         0.82258065]
F1: [0.75121951 0.         0.57303371]
Micro: 0.6095238095238096
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 3.61
  Validation took: 1.932326078414917

Training complete!
Total training took 0:03:18 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917

============ Epoch 5 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.99
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.48214286 0.47       0.09259259]
Recall: [0.48214286 0.48453608 0.0877193 ]
F1: [0.48214286 0.47715736 0.09009009]
Micro: 0.3761904761904762
============================
For --Stance--
Precision: [0.81188119 0.36363636 0.39534884]
Recall: [0.73873874 0.64864865 0.27419355]
F1: [0.77358491 0.46601942 0.32380952]
Micro: 0.5857142857142857
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 3.81
  Validation took: 1.9303967952728271

Training complete!
Total training took 0:03:58 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271

============ Epoch 6 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.85
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.72727273 0.41975309 0.03846154]
Recall: [0.28571429 0.70103093 0.01754386]
F1: [0.41025641 0.52509653 0.02409639]
Micro: 0.40476190476190477
============================
For --Stance--
Precision: [0.82857143 0.56       0.5375    ]
Recall: [0.78378378 0.37837838 0.69354839]
F1: [0.80555556 0.4516129  0.6056338 ]
Micro: 0.6857142857142857
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 4.26
  Validation took: 1.9309172630310059

Training complete!
Total training took 0:04:37 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059

============ Epoch 7 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.83
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.84210526 0.47101449 0.08823529]
Recall: [0.57142857 0.67010309 0.05263158]
F1: [0.68085106 0.55319149 0.06593407]
Micro: 0.47619047619047616
============================
For --Stance--
Precision: [0.9382716  0.41666667 0.44927536]
Recall: [0.68468468 0.67567568 0.5       ]
F1: [0.79166667 0.51546392 0.47328244]
Micro: 0.6285714285714286
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 3.83
  Validation took: 1.9337859153747559

Training complete!
Total training took 0:05:17 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559

============ Epoch 8 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.75
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.86956522 0.44654088 0.10714286]
Recall: [0.35714286 0.73195876 0.05263158]
F1: [0.50632911 0.5546875  0.07058824]
Micro: 0.44761904761904764
============================
For --Stance--
Precision: [0.703125  1.        0.4691358]
Recall: [0.81081081 0.02702703 0.61290323]
F1: [0.75313808 0.05263158 0.53146853]
Micro: 0.6142857142857143
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 5.00
  Validation took: 1.9324657917022705

Training complete!
Total training took 0:05:56 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705

============ Epoch 9 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.74
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.78378378 0.42857143 0.08      ]
Recall: [0.51785714 0.43298969 0.10526316]
F1: [0.62365591 0.43076923 0.09090909]
Micro: 0.36666666666666664
============================
For --Stance--
Precision: [0.88990826 0.44444444 0.61702128]
Recall: [0.87387387 0.64864865 0.46774194]
F1: [0.88181818 0.52747253 0.53211009]
Micro: 0.7142857142857143
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 4.61
  Validation took: 1.9320652484893799

Training complete!
Total training took 0:06:36 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799

============ Epoch 10 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.65
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.72307692 0.58715596 0.13888889]
Recall: [0.83928571 0.65979381 0.0877193 ]
F1: [0.7768595  0.62135922 0.10752688]
Micro: 0.5523809523809524
============================
For --Stance--
Precision: [0.92307692 1.         0.5       ]
Recall: [0.75675676 0.13513514 0.91935484]
F1: [0.83168317 0.23809524 0.64772727]
Micro: 0.6952380952380952
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 4.18
  Validation took: 1.931788444519043

Training complete!
Total training took 0:07:15 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043

============ Epoch 11 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.63
 Training epoch took: 0:00:38

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.79069767 0.5106383  0.11538462]
Recall: [0.60714286 0.74226804 0.05263158]
F1: [0.68686869 0.60504202 0.07228916]
Micro: 0.5190476190476191
============================
For --Stance--
Precision: [0.93103448 0.6        0.49152542]
Recall: [0.72972973 0.08108108 0.93548387]
F1: [0.81818182 0.14285714 0.64444444]
Micro: 0.6761904761904762
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 4.73
  Validation took: 1.9310355186462402

Training complete!
Total training took 0:07:55 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043
11              0.63         4.73       0:00:38  1.9310355186462402

============ Epoch 12 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.59
 Training epoch took: 0:00:37

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.7826087  0.51094891 0.14814815]
Recall: [0.64285714 0.72164948 0.07017544]
F1: [0.70588235 0.5982906  0.0952381 ]
Micro: 0.5238095238095238
============================
For --Stance--
Precision: [0.93333333 0.66666667 0.52777778]
Recall: [0.75675676 0.21621622 0.91935484]
F1: [0.8358209  0.32653061 0.67058824]
Micro: 0.7095238095238096
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 4.56
  Validation took: 1.9306824207305908

Training complete!
Total training took 0:08:34 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043
11              0.63         4.73       0:00:38  1.9310355186462402
12              0.59         4.56       0:00:37  1.9306824207305908

============ Epoch 13 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:30
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.54
 Training epoch took: 0:00:37

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.77358491 0.544      0.125     ]
Recall: [0.73214286 0.70103093 0.07017544]
F1: [0.75229358 0.61261261 0.08988764]
Micro: 0.5380952380952381
============================
For --Stance--
Precision: [0.93406593 0.6        0.5       ]
Recall: [0.76576577 0.08108108 0.91935484]
F1: [0.84158416 0.14285714 0.64772727]
Micro: 0.6904761904761905
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 4.72
  Validation took: 1.9333996772766113

Training complete!
Total training took 0:09:14 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043
11              0.63         4.73       0:00:38  1.9310355186462402
12              0.59         4.56       0:00:37  1.9306824207305908
13              0.54         4.72       0:00:37  1.9333996772766113

============ Epoch 14 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:29
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.51
 Training epoch took: 0:00:37

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.75       0.52142857 0.09090909]
Recall: [0.64285714 0.75257732 0.03508772]
F1: [0.69230769 0.61603376 0.05063291]
Micro: 0.5285714285714286
============================
For --Stance--
Precision: [0.93181818 0.6        0.50892857]
Recall: [0.73873874 0.16216216 0.91935484]
F1: [0.8241206  0.25531915 0.65517241]
Micro: 0.6904761904761905
============================
For --Rebuttal--
Precision: [0.         0.95238095]
Recall: [0. 1.]
F1: [0.         0.97560976]
Micro: 0.9523809523809523
==============================
  Validation Loss: 4.72
  Validation took: 1.9347095489501953

Training complete!
Total training took 0:09:53 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043
11              0.63         4.73       0:00:38  1.9310355186462402
12              0.59         4.56       0:00:37  1.9306824207305908
13              0.54         4.72       0:00:37  1.9333996772766113
14              0.51         4.72       0:00:37  1.9347095489501953

============ Epoch 15 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:29
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.49
 Training epoch took: 0:00:37

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.703125   0.56779661 0.14285714]
Recall: [0.80357143 0.69072165 0.07017544]
F1: [0.75       0.62325581 0.09411765]
Micro: 0.5523809523809524
============================
For --Stance--
Precision: [0.92134831 0.5        0.51456311]
Recall: [0.73873874 0.24324324 0.85483871]
F1: [0.82       0.32727273 0.64242424]
Micro: 0.6857142857142857
============================
For --Rebuttal--
Precision: [0.11111111 0.95522388]
Recall: [0.1  0.96]
F1: [0.10526316 0.95760599]
Micro: 0.919047619047619
==============================
  Validation Loss: 4.76
  Validation took: 1.931067705154419

Training complete!
Total training took 0:10:32 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043
11              0.63         4.73       0:00:38  1.9310355186462402
12              0.59         4.56       0:00:37  1.9306824207305908
13              0.54         4.72       0:00:37  1.9333996772766113
14              0.51         4.72       0:00:37  1.9347095489501953
15              0.49         4.76       0:00:37   1.931067705154419

============ Epoch 16 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:29
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.44
 Training epoch took: 0:00:37

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.74509804 0.52173913 0.0952381 ]
Recall: [0.67857143 0.74226804 0.03508772]
F1: [0.71028037 0.61276596 0.05128205]
Micro: 0.5333333333333333
============================
For --Stance--
Precision: [0.93181818 0.71428571 0.49565217]
Recall: [0.73873874 0.13513514 0.91935484]
F1: [0.8241206  0.22727273 0.6440678 ]
Micro: 0.6857142857142857
============================
For --Rebuttal--
Precision: [1.        0.9569378]
Recall: [0.1 1. ]
F1: [0.18181818 0.97799511]
Micro: 0.9571428571428572
==============================
  Validation Loss: 4.95
  Validation took: 1.931417465209961

Training complete!
Total training took 0:11:11 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043
11              0.63         4.73       0:00:38  1.9310355186462402
12              0.59         4.56       0:00:37  1.9306824207305908
13              0.54         4.72       0:00:37  1.9333996772766113
14              0.51         4.72       0:00:37  1.9347095489501953
15              0.49         4.76       0:00:37   1.931067705154419
16              0.44         4.95       0:00:37   1.931417465209961

============ Epoch 17 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:29
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.42
 Training epoch took: 0:00:37

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.73333333 0.54918033 0.14285714]
Recall: [0.78571429 0.69072165 0.07017544]
F1: [0.75862069 0.61187215 0.09411765]
Micro: 0.5476190476190477
============================
For --Stance--
Precision: [0.91489362 0.68421053 0.53608247]
Recall: [0.77477477 0.35135135 0.83870968]
F1: [0.83902439 0.46428571 0.65408805]
Micro: 0.719047619047619
============================
For --Rebuttal--
Precision: [0.30769231 0.96954315]
Recall: [0.4   0.955]
F1: [0.34782609 0.96221662]
Micro: 0.9285714285714286
==============================
  Validation Loss: 4.88
  Validation took: 1.930351972579956

Training complete!
Total training took 0:11:51 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043
11              0.63         4.73       0:00:38  1.9310355186462402
12              0.59         4.56       0:00:37  1.9306824207305908
13              0.54         4.72       0:00:37  1.9333996772766113
14              0.51         4.72       0:00:37  1.9347095489501953
15              0.49         4.76       0:00:37   1.931067705154419
16              0.44         4.95       0:00:37   1.931417465209961
17              0.42         4.88       0:00:37   1.930351972579956

============ Epoch 18 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:29
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.36
 Training epoch took: 0:00:37

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.78431373 0.52985075 0.16      ]
Recall: [0.71428571 0.73195876 0.07017544]
F1: [0.74766355 0.61471861 0.09756098]
Micro: 0.5476190476190477
============================
For --Stance--
Precision: [0.92631579 0.68421053 0.55208333]
Recall: [0.79279279 0.35135135 0.85483871]
F1: [0.85436893 0.46428571 0.67088608]
Micro: 0.7333333333333333
============================
For --Rebuttal--
Precision: [0.2        0.95609756]
Recall: [0.1  0.98]
F1: [0.13333333 0.96790123]
Micro: 0.9380952380952381
==============================
  Validation Loss: 4.88
  Validation took: 1.933208703994751

Training complete!
Total training took 0:12:30 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043
11              0.63         4.73       0:00:38  1.9310355186462402
12              0.59         4.56       0:00:37  1.9306824207305908
13              0.54         4.72       0:00:37  1.9333996772766113
14              0.51         4.72       0:00:37  1.9347095489501953
15              0.49         4.76       0:00:37   1.931067705154419
16              0.44         4.95       0:00:37   1.931417465209961
17              0.42         4.88       0:00:37   1.930351972579956
18              0.36         4.88       0:00:37   1.933208703994751

============ Epoch 19 / 20 ============
Training...
Batch   75 of   381. Elapsed: 0:00:07
Batch  150 of   381. Elapsed: 0:00:15
Batch  225 of   381. Elapsed: 0:00:22
Batch  300 of   381. Elapsed: 0:00:29
Batch  375 of   381. Elapsed: 0:00:37

 Average training loss: 0.36
 Training epoch took: 0:00:37

Running Validation...
Batch   40 of    53.
============================
For --Severity--
Precision: [0.77777778 0.53846154 0.15384615]
Recall: [0.75       0.72164948 0.07017544]
F1: [0.76363636 0.61674009 0.09638554]
Micro: 0.5523809523809524
============================
For --Stance--
Precision: [0.91666667 0.66666667 0.54166667]
Recall: [0.79279279 0.32432432 0.83870968]
F1: [0.85024155 0.43636364 0.65822785]
Micro: 0.7238095238095238
============================
For --Rebuttal--
Precision: [0.125      0.95544554]
Recall: [0.1   0.965]
F1: [0.11111111 0.960199  ]
Micro: 0.9238095238095239
==============================
  Validation Loss: 4.89
  Validation took: 1.9333064556121826

Training complete!
Total training took 0:13:09 (h:mm:ss)
       Training Loss  Valid. Loss Training Time     Validation Time
epoch                                                              
0               1.95         2.35       0:00:38  1.9341628551483154
1               1.93         2.53       0:00:38  1.9329569339752197
2               1.58         2.58       0:00:38  1.9326908588409424
3               1.29         4.91       0:00:38  1.9320955276489258
4               1.15         3.61       0:00:38   1.932326078414917
5               0.99         3.81       0:00:38  1.9303967952728271
6               0.85         4.26       0:00:38  1.9309172630310059
7               0.83         3.83       0:00:38  1.9337859153747559
8               0.75         5.00       0:00:38  1.9324657917022705
9               0.74         4.61       0:00:38  1.9320652484893799
10              0.65         4.18       0:00:38   1.931788444519043
11              0.63         4.73       0:00:38  1.9310355186462402
12              0.59         4.56       0:00:37  1.9306824207305908
13              0.54         4.72       0:00:37  1.9333996772766113
14              0.51         4.72       0:00:37  1.9347095489501953
15              0.49         4.76       0:00:37   1.931067705154419
16              0.44         4.95       0:00:37   1.931417465209961
17              0.42         4.88       0:00:37   1.930351972579956
18              0.36         4.88       0:00:37   1.933208703994751
19              0.36         4.89       0:00:37  1.9333064556121826
